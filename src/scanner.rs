use std::iter::FusedIterator;

use crate::token::{Token, TokenType};

#[derive(Debug, Clone)]
pub struct Scanner<'a> {
    source: &'a [u8],
    start: usize,
    curr_ptr: usize,
    line: usize,
    had_error: bool,
    pending_token: Option<TokenType>,
}

impl<'a> Scanner<'a> {
    pub fn new(buf: &'a [u8]) -> Self {
        Self {
            source: buf,
            start: 0,
            curr_ptr: 0,
            line: 1,
            had_error: false,
            pending_token: None,
        }
    }

    #[inline]
    const fn len(&self) -> usize {
        self.source.len()
    }

    fn scan_token(&mut self) -> Result<(), String> {
        let byte: u8 = self.advance();

        match byte {
            b'(' => self.add_token(TokenType::LEFT_PAREN),

            b')' => self.add_token(TokenType::RIGHT_PAREN),

            b'{' => self.add_token(TokenType::LEFT_BRACE),

            b'}' => self.add_token(TokenType::RIGHT_BRACE),

            b',' => self.add_token(TokenType::COMMA),

            b'.' => self.add_token(TokenType::DOT),

            b'-' => self.add_token(TokenType::MINUS),

            b'+' => self.add_token(TokenType::PLUS),

            b';' => self.add_token(TokenType::SEMICOLON),

            b'/' => self.add_token(TokenType::SLASH),

            b'*' => self.add_token(TokenType::STAR),

            b'!' => {
                let token_type: TokenType = if self.match_byte(b'=') {
                    TokenType::BANG_EQUAL
                } else {
                    TokenType::BANG
                };

                self.add_token(token_type);
            }

            b'=' => {
                let token_type: TokenType = if self.match_byte(b'=') {
                    TokenType::EQUAL_EQUAL
                } else {
                    TokenType::EQUAL
                };

                self.add_token(token_type);
            }

            b'<' => {
                let token_type: TokenType = if self.match_byte(b'=') {
                    TokenType::LESS_EQUAL
                } else {
                    TokenType::LESS
                };

                self.add_token(token_type);
            }

            b'>' => {
                let token_type: TokenType = if self.match_byte(b'=') {
                    TokenType::GREATER_EQUAL
                } else {
                    TokenType::GREATER
                };

                self.add_token(token_type);
            }

            _ => {
                self.had_error = true;

                return Err(format!(
                    "[line {}] Error: Unexpected character: {}",
                    self.line, byte as char
                ));
            }
        }

        Ok(())
    }

    ///
    /// Set the current pending_token as the given token type.
    ///
    /// This allows us to consume this Token through the Iterator API.
    ///
    #[inline]
    fn add_token(&mut self, token_type: TokenType) {
        self.pending_token = Some(token_type);
    }

    ///
    /// Temporarily stores the current byte.
    ///
    /// Advances the buffer pointer by 1, pointing to the next byte in the stream
    ///
    /// Returns the stored byte.
    ///
    #[inline]
    fn advance(&mut self) -> u8 {
        let byte = self.source[self.curr_ptr];
        self.curr_ptr += 1;

        byte
    }

    ///
    /// Ensures that the lexeme generated by the next call of Iterator
    /// includes the next character if a next matching byte is found.
    ///
    ///
    #[inline]
    fn match_byte(&mut self, expected: u8) -> bool {
        if self.is_at_end() || self.source[self.curr_ptr] != expected {
            false
        } else {
            self.curr_ptr += 1;
            true
        }
    }

    #[inline]
    fn is_at_end(&self) -> bool {
        self.curr_ptr >= self.len()
    }
}

impl<'a> Iterator for Scanner<'a> {
    type Item = Result<Token<'a>, String>;

    ///
    /// ------- Part 1: Buffer Proces State -------
    /// - If the buffer pointer is at the end of file
    ///    - If the pointer is equal to the length of buffer
    ///         - Increment the pointer by 1 to indicate buffer was fully processed.
    ///         - Return Option<Result<Token(EOF)>>
    ///    - Else always return None (In general, Rust iterators are expected to always return None when it is fully consumed)
    ///
    /// ------- Part 2: Scan Current Token -------
    /// - Set self.pending_token = None ()
    ///
    ///
    ///
    fn next(&mut self) -> Option<Self::Item> {
        if self.is_at_end() {
            if self.curr_ptr == self.len() {
                self.curr_ptr += 1;
                return Some(Ok(Token::new(TokenType::EOF, "", self.line)));
            }

            return None;
        }

        self.pending_token = None;
        self.start = self.curr_ptr;

        let result: Result<(), String> = self.scan_token();

        if let Err(e) = result {
            self.had_error = true;

            return Some(Err(e));
        }

        if let Some(token_type) = self.pending_token.take() {
            let lexeme =
                unsafe { std::str::from_utf8_unchecked(&self.source[self.start..self.curr_ptr]) };

            Some(Ok(Token::new(token_type, lexeme, self.line)))
        } else {
            self.next() // Recursively keep calling next until EOF is reached
        }
    }
}

impl<'a> FusedIterator for Scanner<'a> {}
